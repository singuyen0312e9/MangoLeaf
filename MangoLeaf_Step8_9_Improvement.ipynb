{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# BƯỚC 8 & 9: NÂNG CẤP SIÊU CẤP - SHUFFLENETV2 WITH CBAM ATTENTION\n",
                "--- \n",
                "### 1. Mục tiêu tối thượng\n",
                "- **Yêu cầu:** Nhận diện chính xác các vùng bệnh nhỏ nhất, vượt qua hiệu suất của mô hình ConvNeXtTiny.\n",
                "- **Công nghệ:** Tích hợp **CBAM (Convolutional Block Attention Module)** vào ShuffleNetV2 để mô hình có khả năng 'tập trung ánh nhìn' vào vết bệnh.\n",
                "\n",
                "### 2. So sánh đặc tính kỹ thuật\n",
                "\n",
                "| Thành phần | ShuffleNetV2 (Cải tiến cũ) | **ShuffleNetV2 + CBAM (MỚI)** |\n",
                "| :--- | :--- | :--- |\n",
                "| **Attention Module** | Không có | **CBAM (Channel + Spatial)** - Tập trung vùng bệnh nhỏ |\n",
                "| **Khả năng quan sát** | Toàn cục (Global) | **Địa phương (Local-Focus)** - Soi chi tiết các đốm bệnh |\n",
                "| **Độ ổn định** | Trung bình | **Rất cao** (Bỏ qua nhiễu phông nền, Logo) |\n",
                "| **Optimizer** | AdamW | **AdamW + OneCycleLR** (Tối ưu nhất hiện nay) |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, torch, json, cv2, random, numpy as np, matplotlib.pyplot as plt\n",
                "from torchvision import datasets, transforms, models\n",
                "from torch.utils.data import DataLoader\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
                "import seaborn as sns\n",
                "from tqdm import tqdm\n",
                "\n",
                "# --- ĐỊNH NGHĨA MODULE ATTENTION CBAM ---\n",
                "class ChannelAttention(nn.Module):\n",
                "    def __init__(self, in_planes, ratio=16):\n",
                "        super(ChannelAttention, self).__init__()\n",
                "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
                "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
                "        self.fc = nn.Sequential(\n",
                "            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
                "            nn.ReLU(),\n",
                "            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
                "        )\n",
                "        self.sigmoid = nn.Sigmoid()\n",
                "    def forward(self, x):\n",
                "        avg_out = self.fc(self.avg_pool(x))\n",
                "        max_out = self.fc(self.max_pool(x))\n",
                "        return self.sigmoid(avg_out + max_out)\n",
                "\n",
                "class SpatialAttention(nn.Module):\n",
                "    def __init__(self, kernel_size=7):\n",
                "        super(SpatialAttention, self).__init__()\n",
                "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
                "        self.sigmoid = nn.Sigmoid()\n",
                "    def forward(self, x):\n",
                "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
                "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
                "        concat = torch.cat([avg_out, max_out], dim=1)\n",
                "        return self.sigmoid(self.conv(concat))\n",
                "\n",
                "# --- GHÉP CBAM VÀO SHUFFLENETV2 ---\n",
                "class CBAMShuffleNetV2(nn.Module):\n",
                "    def __init__(self, num_classes):\n",
                "        super().__init__()\n",
                "        base = models.shufflenet_v2_x1_0(weights='DEFAULT')\n",
                "        self.conv1 = base.conv1\n",
                "        self.maxpool = base.maxpool\n",
                "        self.stage2 = base.stage2\n",
                "        self.stage3 = base.stage3\n",
                "        self.stage4 = base.stage4\n",
                "        self.conv5 = base.conv5\n",
                "        self.ca = ChannelAttention(464) \n",
                "        self.sa = SpatialAttention()\n",
                "        self.fc = nn.Sequential(\n",
                "            nn.Linear(1024, 512),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(512, num_classes)\n",
                "        )\n",
                "    def forward(self, x):\n",
                "        x = self.conv1(x); x = self.maxpool(x)\n",
                "        x = self.stage2(x); x = self.stage3(x); x = self.stage4(x)\n",
                "        x = x * self.ca(x); x = x * self.sa(x)\n",
                "        x = self.conv5(x); x = x.mean([2, 3]); x = self.fc(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## BƯỚC 8: Huấn luyện với Kỹ thuật Tinh chỉnh và Attention"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "BASE_PATH = r'd:\\HUTECH\\AI\\DeepLearning\\DAHS\\MangoLeaf'\n",
                "DST_PATH = os.path.join(BASE_PATH, 'dataset_scientific_split')\n",
                "RESULT_PATH = os.path.join(BASE_PATH, 'Result', 'ShuffleNetV2_CBAM_Improved')\n",
                "os.makedirs(RESULT_PATH, exist_ok=True)\n",
                "\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "BATCH_SIZE = 32; EPOCHS = 30\n",
                "\n",
                "train_transform = transforms.Compose([\n",
                "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomRotation(20),\n",
                "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "val_transform = transforms.Compose([\n",
                "    transforms.Resize((224, 224)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "train_loader = DataLoader(datasets.ImageFolder(os.path.join(DST_PATH, 'train'), train_transform), batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
                "val_loader = DataLoader(datasets.ImageFolder(os.path.join(DST_PATH, 'val'), val_transform), batch_size=BATCH_SIZE, shuffle=False)\n",
                "test_loader = DataLoader(datasets.ImageFolder(os.path.join(DST_PATH, 'test'), val_transform), batch_size=BATCH_SIZE, shuffle=False)\n",
                "\n",
                "CLASS_NAMES = datasets.ImageFolder(os.path.join(DST_PATH, 'train')).classes\n",
                "NUM_CLASSES = len(CLASS_NAMES)\n",
                "\n",
                "model = CBAMShuffleNetV2(NUM_CLASSES).to(DEVICE)\n",
                "optimizer = optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.01)\n",
                "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
                "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.0006, steps_per_epoch=len(train_loader), epochs=EPOCHS)\n",
                "scaler = torch.cuda.amp.GradScaler()\n",
                "\n",
                "best_acc = 0\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train(); tr_loss = 0\n",
                "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS}')\n",
                "    for inputs, labels in pbar:\n",
                "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        with torch.cuda.amp.autocast():\n",
                "            outputs = model(inputs); loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
                "        scheduler.step(); tr_loss += loss.item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    model.eval(); v_correct = 0\n",
                "    with torch.no_grad():\n",
                "        for inputs, labels in val_loader:\n",
                "            out = model(inputs.to(DEVICE)); v_correct += (out.argmax(1) == labels.to(DEVICE)).sum().item()\n",
                "    \n",
                "    val_acc = v_correct / len(val_loader.dataset)\n",
                "    print(f'>>> Val Acc: {val_acc:.4f}')\n",
                "    if val_acc >= best_acc:\n",
                "        best_acc = val_acc\n",
                "        torch.save(model.state_dict(), os.path.join(RESULT_PATH, 'best_shufflenet_cbam.pth'))\n",
                "        print('Saved Best Attention Model!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## BƯỚC 9: Đánh giá chi tiết hiệu năng cải tiến"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9080\\1576763042.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
                        "  model.load_state_dict(torch.load(os.path.join(RESULT_PATH, 'best_shufflenet_cbam.pth')))\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                  precision    recall  f1-score   support\n",
                        "\n",
                        "     Anthracnose       0.97      1.00      0.99        39\n",
                        "Bacterial_Canker       1.00      1.00      1.00        40\n",
                        "  Bacterial_Spot       0.98      1.00      0.99        40\n",
                        "  Cutting_Weevil       1.00      1.00      1.00        40\n",
                        "        Die_Back       1.00      1.00      1.00        41\n",
                        "      Gall_Midge       1.00      0.95      0.97        40\n",
                        "         Healthy       1.00      1.00      1.00        40\n",
                        "  Powdery_Mildew       1.00      1.00      1.00        40\n",
                        "     Sooty_Mould       1.00      1.00      1.00        40\n",
                        "\n",
                        "        accuracy                           0.99       360\n",
                        "       macro avg       0.99      0.99      0.99       360\n",
                        "    weighted avg       0.99      0.99      0.99       360\n",
                        "\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'confusion_matrix' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m         y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m cm = \u001b[43mconfusion_matrix\u001b[49m(y_true, y_pred)\n\u001b[32m     10\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m8\u001b[39m)); sns.heatmap(cm, annot=\u001b[38;5;28;01mTrue\u001b[39;00m, fmt=\u001b[33m'\u001b[39m\u001b[33md\u001b[39m\u001b[33m'\u001b[39m, xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES); plt.show()\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Lưu báo cáo cuối cùng\u001b[39;00m\n",
                        "\u001b[31mNameError\u001b[39m: name 'confusion_matrix' is not defined"
                    ]
                }
            ],
            "source": [
                "model.load_state_dict(torch.load(os.path.join(RESULT_PATH, 'best_shufflenet_cbam.pth')))\n",
                "model.eval(); y_true, y_pred = [], []\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        outputs = model(inputs.to(DEVICE)); preds = outputs.argmax(1)\n",
                "        y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n",
                "\n",
                "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
                "cm = confusion_matrix(y_true, y_pred)\n",
                "plt.figure(figsize=(10, 8)); sns.heatmap(cm, annot=True, fmt='d', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES); plt.show()\n",
                "\n",
                "# Lưu báo cáo cuối cùng\n",
                "report_data = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
                "with open(os.path.join(RESULT_PATH, 'report.json'), 'w') as f: json.dump(report_data, f, indent=4)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
