{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Báo cáo Khoa học - Đã tối ưu tốc độ\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, hashlib, shutil, random, cv2, torch, json\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from torchvision import datasets, transforms, models\n",
                "from torch.utils.data import DataLoader\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support, mean_squared_error, r2_score\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Cấu hình hệ thống\n",
                "BASE_PATH = r'd:\\HUTECH\\AI\\DeepLearning\\DAHS\\MangoLeaf'\n",
                "DST_PATH = os.path.join(BASE_PATH, 'dataset_scientific_split')\n",
                "RESULT_PATH = os.path.join(BASE_PATH, 'Result')\n",
                "IMG_SIZE = 224; BATCH_SIZE = 32; EPOCHS = 30\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "torch.backends.cudnn.benchmark = True\n",
                "\n",
                "transform = transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "train_set = datasets.ImageFolder(os.path.join(DST_PATH, 'train'), transform=transform)\n",
                "val_set = datasets.ImageFolder(os.path.join(DST_PATH, 'val'), transform=transform)\n",
                "test_set = datasets.ImageFolder(os.path.join(DST_PATH, 'test'), transform=transform)\n",
                "\n",
                "# Tối ưu nạp dữ liệu\n",
                "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
                "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
                "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
                "\n",
                "CLASS_NAMES = train_set.classes; NUM_CLASSES = len(CLASS_NAMES)\n",
                "\n",
                "def get_model(name, num_classes):\n",
                "    if name == 'SimpleCNN': m = nn.Sequential(nn.Conv2d(3,32,3,1), nn.ReLU(), nn.MaxPool2d(2), nn.Flatten(), nn.Linear(32*111*111, num_classes))\n",
                "    elif name == 'AlexNet': m = models.alexnet(weights='DEFAULT'); m.classifier[6] = nn.Linear(4096, num_classes)\n",
                "    elif name == 'MobileNetV2': m = models.mobilenet_v2(weights='DEFAULT'); m.classifier[1] = nn.Linear(1280, num_classes)\n",
                "    elif name == 'MobileNetV3': m = models.mobilenet_v3_small(weights='DEFAULT'); m.classifier[3] = nn.Linear(1024, num_classes)\n",
                "    elif name == 'ResNet18': m = models.resnet18(weights='DEFAULT'); m.fc = nn.Linear(512, num_classes)\n",
                "    elif name == 'ResNet50': m = models.resnet50(weights='DEFAULT'); m.fc = nn.Linear(2048, num_classes)\n",
                "    elif name == 'ShuffleNetV2': m = models.shufflenet_v2_x1_0(weights='DEFAULT'); m.fc = nn.Linear(1024, num_classes)\n",
                "    elif name == 'DenseNet121': m = models.densenet121(weights='DEFAULT'); m.classifier = nn.Linear(1024, num_classes)\n",
                "    elif name == 'EfficientNetV2': m = models.efficientnet_v2_s(weights='DEFAULT'); m.classifier[1] = nn.Linear(1280, num_classes)\n",
                "    elif name == 'ConvNeXt_Tiny': m = models.convnext_tiny(weights='DEFAULT'); m.classifier[2] = nn.Linear(768, num_classes)\n",
                "    return m.to(DEVICE)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Mô hình: SimpleCNN\n",
                "**Mô tả:** Baseline 2 lớp Conv.\n",
                "\n",
                "**Tối ưu hóa:** Sử dụng Mixed Precision (AMP) và Multi-worker DataLoading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Huấn luyện TỐI ƯU mô hình: SimpleCNN\n",
                "m_name = 'SimpleCNN'\n",
                "m_res_path = os.path.join(RESULT_PATH, m_name)\n",
                "os.makedirs(m_res_path, exist_ok=True)\n",
                "\n",
                "print(f'--- Đang khởi tạo mô hình: {m_name} ---')\n",
                "model = get_model(m_name, NUM_CLASSES)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
                "scaler = torch.cuda.amp.GradScaler() # AMP\n",
                "\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train(); tr_loss, tr_correct = 0, 0\n",
                "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Train]')\n",
                "    for inputs, labels in pbar:\n",
                "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        with torch.cuda.amp.autocast(): # AMP Forward\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward() # AMP Backward\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        tr_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "        tr_correct += (preds == labels.data).sum().item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    model.eval(); v_loss, v_correct = 0, 0\n",
                "    with torch.no_grad():\n",
                "        vbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Val]')\n",
                "        for inputs, labels in vbar:\n",
                "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "            with torch.cuda.amp.autocast():\n",
                "                outputs = model(inputs); loss = criterion(outputs, labels)\n",
                "            v_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "            v_correct += (preds == labels.data).sum().item()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss/len(train_loader))\n",
                "    history['val_loss'].append(v_loss/len(val_loader))\n",
                "    history['train_acc'].append(tr_correct/len(train_set))\n",
                "    history['val_acc'].append(v_correct/len(val_set))\n",
                "\n",
                "# TÍNH TOÁN METRICS\n",
                "y_true, y_pred = [], []\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        outputs = model(inputs.to(DEVICE)); _, preds = torch.max(outputs, 1)\n",
                "        y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n",
                "\n",
                "acc = accuracy_score(y_true, y_pred)\n",
                "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
                "mse = mean_squared_error(y_true, y_pred); rmse = np.sqrt(mse); r2 = r2_score(y_true, y_pred)\n",
                "\n",
                "# LƯU KẾT QUẢ\n",
                "report_data = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
                "report_data['regression_metrics'] = {'mse': float(mse), 'rmse': float(rmse), 'r2_score': float(r2), 'accuracy': float(acc)}\n",
                "with open(os.path.join(m_res_path, 'report.json'), 'w') as f: json.dump(report_data, f, indent=4)\n",
                "\n",
                "# VẼ BIỂU ĐỒ TỔNG HỢP CHO MODEL\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "axes[0].plot(history['train_acc'], label='Train Acc'); axes[0].plot(history['val_acc'], label='Val Acc'); axes[0].set_title('Accuracy'); axes[0].legend()\n",
                "axes[1].plot(history['train_loss'], label='Train Loss'); axes[1].plot(history['val_loss'], label='Val Loss'); axes[1].set_title('Loss'); axes[1].legend()\n",
                "plt.savefig(os.path.join(m_res_path, 'metrics_curves.png')); plt.show()\n",
                "\n",
                "print(f'Done {m_name}: Accuracy={acc:.4f}')\n",
                "del model; torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Mô hình: AlexNet\n",
                "**Mô tả:** Cổ điển mạnh mẽ.\n",
                "\n",
                "**Tối ưu hóa:** Sử dụng Mixed Precision (AMP) và Multi-worker DataLoading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Huấn luyện TỐI ƯU mô hình: AlexNet\n",
                "m_name = 'AlexNet'\n",
                "m_res_path = os.path.join(RESULT_PATH, m_name)\n",
                "os.makedirs(m_res_path, exist_ok=True)\n",
                "\n",
                "print(f'--- Đang khởi tạo mô hình: {m_name} ---')\n",
                "model = get_model(m_name, NUM_CLASSES)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
                "scaler = torch.cuda.amp.GradScaler() # AMP\n",
                "\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train(); tr_loss, tr_correct = 0, 0\n",
                "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Train]')\n",
                "    for inputs, labels in pbar:\n",
                "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        with torch.cuda.amp.autocast(): # AMP Forward\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward() # AMP Backward\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        tr_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "        tr_correct += (preds == labels.data).sum().item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    model.eval(); v_loss, v_correct = 0, 0\n",
                "    with torch.no_grad():\n",
                "        vbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Val]')\n",
                "        for inputs, labels in vbar:\n",
                "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "            with torch.cuda.amp.autocast():\n",
                "                outputs = model(inputs); loss = criterion(outputs, labels)\n",
                "            v_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "            v_correct += (preds == labels.data).sum().item()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss/len(train_loader))\n",
                "    history['val_loss'].append(v_loss/len(val_loader))\n",
                "    history['train_acc'].append(tr_correct/len(train_set))\n",
                "    history['val_acc'].append(v_correct/len(val_set))\n",
                "\n",
                "# TÍNH TOÁN METRICS\n",
                "y_true, y_pred = [], []\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        outputs = model(inputs.to(DEVICE)); _, preds = torch.max(outputs, 1)\n",
                "        y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n",
                "\n",
                "acc = accuracy_score(y_true, y_pred)\n",
                "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
                "mse = mean_squared_error(y_true, y_pred); rmse = np.sqrt(mse); r2 = r2_score(y_true, y_pred)\n",
                "\n",
                "# LƯU KẾT QUẢ\n",
                "report_data = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
                "report_data['regression_metrics'] = {'mse': float(mse), 'rmse': float(rmse), 'r2_score': float(r2), 'accuracy': float(acc)}\n",
                "with open(os.path.join(m_res_path, 'report.json'), 'w') as f: json.dump(report_data, f, indent=4)\n",
                "\n",
                "# VẼ BIỂU ĐỒ TỔNG HỢP CHO MODEL\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "axes[0].plot(history['train_acc'], label='Train Acc'); axes[0].plot(history['val_acc'], label='Val Acc'); axes[0].set_title('Accuracy'); axes[0].legend()\n",
                "axes[1].plot(history['train_loss'], label='Train Loss'); axes[1].plot(history['val_loss'], label='Val Loss'); axes[1].set_title('Loss'); axes[1].legend()\n",
                "plt.savefig(os.path.join(m_res_path, 'metrics_curves.png')); plt.show()\n",
                "\n",
                "print(f'Done {m_name}: Accuracy={acc:.4f}')\n",
                "del model; torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Mô hình: MobileNetV2\n",
                "**Mô tả:** Tối ưu di động.\n",
                "\n",
                "**Tối ưu hóa:** Sử dụng Mixed Precision (AMP) và Multi-worker DataLoading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Huấn luyện TỐI ƯU mô hình: MobileNetV2\n",
                "m_name = 'MobileNetV2'\n",
                "m_res_path = os.path.join(RESULT_PATH, m_name)\n",
                "os.makedirs(m_res_path, exist_ok=True)\n",
                "\n",
                "print(f'--- Đang khởi tạo mô hình: {m_name} ---')\n",
                "model = get_model(m_name, NUM_CLASSES)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
                "scaler = torch.cuda.amp.GradScaler() # AMP\n",
                "\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train(); tr_loss, tr_correct = 0, 0\n",
                "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Train]')\n",
                "    for inputs, labels in pbar:\n",
                "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        with torch.cuda.amp.autocast(): # AMP Forward\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward() # AMP Backward\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        tr_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "        tr_correct += (preds == labels.data).sum().item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    model.eval(); v_loss, v_correct = 0, 0\n",
                "    with torch.no_grad():\n",
                "        vbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Val]')\n",
                "        for inputs, labels in vbar:\n",
                "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "            with torch.cuda.amp.autocast():\n",
                "                outputs = model(inputs); loss = criterion(outputs, labels)\n",
                "            v_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "            v_correct += (preds == labels.data).sum().item()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss/len(train_loader))\n",
                "    history['val_loss'].append(v_loss/len(val_loader))\n",
                "    history['train_acc'].append(tr_correct/len(train_set))\n",
                "    history['val_acc'].append(v_correct/len(val_set))\n",
                "\n",
                "# TÍNH TOÁN METRICS\n",
                "y_true, y_pred = [], []\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        outputs = model(inputs.to(DEVICE)); _, preds = torch.max(outputs, 1)\n",
                "        y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n",
                "\n",
                "acc = accuracy_score(y_true, y_pred)\n",
                "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
                "mse = mean_squared_error(y_true, y_pred); rmse = np.sqrt(mse); r2 = r2_score(y_true, y_pred)\n",
                "\n",
                "# LƯU KẾT QUẢ\n",
                "report_data = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
                "report_data['regression_metrics'] = {'mse': float(mse), 'rmse': float(rmse), 'r2_score': float(r2), 'accuracy': float(acc)}\n",
                "with open(os.path.join(m_res_path, 'report.json'), 'w') as f: json.dump(report_data, f, indent=4)\n",
                "\n",
                "# VẼ BIỂU ĐỒ TỔNG HỢP CHO MODEL\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "axes[0].plot(history['train_acc'], label='Train Acc'); axes[0].plot(history['val_acc'], label='Val Acc'); axes[0].set_title('Accuracy'); axes[0].legend()\n",
                "axes[1].plot(history['train_loss'], label='Train Loss'); axes[1].plot(history['val_loss'], label='Val Loss'); axes[1].set_title('Loss'); axes[1].legend()\n",
                "plt.savefig(os.path.join(m_res_path, 'metrics_curves.png')); plt.show()\n",
                "\n",
                "print(f'Done {m_name}: Accuracy={acc:.4f}')\n",
                "del model; torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Mô hình: MobileNetV3\n",
                "**Mô tả:** Thế hệ MobileNet mới nhất.\n",
                "\n",
                "**Tối ưu hóa:** Sử dụng Mixed Precision (AMP) và Multi-worker DataLoading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Huấn luyện TỐI ƯU mô hình: MobileNetV3\n",
                "m_name = 'MobileNetV3'\n",
                "m_res_path = os.path.join(RESULT_PATH, m_name)\n",
                "os.makedirs(m_res_path, exist_ok=True)\n",
                "\n",
                "print(f'--- Đang khởi tạo mô hình: {m_name} ---')\n",
                "model = get_model(m_name, NUM_CLASSES)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
                "scaler = torch.cuda.amp.GradScaler() # AMP\n",
                "\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train(); tr_loss, tr_correct = 0, 0\n",
                "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Train]')\n",
                "    for inputs, labels in pbar:\n",
                "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        with torch.cuda.amp.autocast(): # AMP Forward\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward() # AMP Backward\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        tr_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "        tr_correct += (preds == labels.data).sum().item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    model.eval(); v_loss, v_correct = 0, 0\n",
                "    with torch.no_grad():\n",
                "        vbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Val]')\n",
                "        for inputs, labels in vbar:\n",
                "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "            with torch.cuda.amp.autocast():\n",
                "                outputs = model(inputs); loss = criterion(outputs, labels)\n",
                "            v_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "            v_correct += (preds == labels.data).sum().item()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss/len(train_loader))\n",
                "    history['val_loss'].append(v_loss/len(val_loader))\n",
                "    history['train_acc'].append(tr_correct/len(train_set))\n",
                "    history['val_acc'].append(v_correct/len(val_set))\n",
                "\n",
                "# TÍNH TOÁN METRICS\n",
                "y_true, y_pred = [], []\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        outputs = model(inputs.to(DEVICE)); _, preds = torch.max(outputs, 1)\n",
                "        y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n",
                "\n",
                "acc = accuracy_score(y_true, y_pred)\n",
                "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
                "mse = mean_squared_error(y_true, y_pred); rmse = np.sqrt(mse); r2 = r2_score(y_true, y_pred)\n",
                "\n",
                "# LƯU KẾT QUẢ\n",
                "report_data = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
                "report_data['regression_metrics'] = {'mse': float(mse), 'rmse': float(rmse), 'r2_score': float(r2), 'accuracy': float(acc)}\n",
                "with open(os.path.join(m_res_path, 'report.json'), 'w') as f: json.dump(report_data, f, indent=4)\n",
                "\n",
                "# VẼ BIỂU ĐỒ TỔNG HỢP CHO MODEL\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "axes[0].plot(history['train_acc'], label='Train Acc'); axes[0].plot(history['val_acc'], label='Val Acc'); axes[0].set_title('Accuracy'); axes[0].legend()\n",
                "axes[1].plot(history['train_loss'], label='Train Loss'); axes[1].plot(history['val_loss'], label='Val Loss'); axes[1].set_title('Loss'); axes[1].legend()\n",
                "plt.savefig(os.path.join(m_res_path, 'metrics_curves.png')); plt.show()\n",
                "\n",
                "print(f'Done {m_name}: Accuracy={acc:.4f}')\n",
                "del model; torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Mô hình: ResNet18\n",
                "**Mô tả:** Residual depth 18.\n",
                "\n",
                "**Tối ưu hóa:** Sử dụng Mixed Precision (AMP) và Multi-worker DataLoading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Huấn luyện TỐI ƯU mô hình: ResNet18\n",
                "m_name = 'ResNet18'\n",
                "m_res_path = os.path.join(RESULT_PATH, m_name)\n",
                "os.makedirs(m_res_path, exist_ok=True)\n",
                "\n",
                "print(f'--- Đang khởi tạo mô hình: {m_name} ---')\n",
                "model = get_model(m_name, NUM_CLASSES)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
                "scaler = torch.cuda.amp.GradScaler() # AMP\n",
                "\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train(); tr_loss, tr_correct = 0, 0\n",
                "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Train]')\n",
                "    for inputs, labels in pbar:\n",
                "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        with torch.cuda.amp.autocast(): # AMP Forward\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward() # AMP Backward\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        tr_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "        tr_correct += (preds == labels.data).sum().item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    model.eval(); v_loss, v_correct = 0, 0\n",
                "    with torch.no_grad():\n",
                "        vbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Val]')\n",
                "        for inputs, labels in vbar:\n",
                "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "            with torch.cuda.amp.autocast():\n",
                "                outputs = model(inputs); loss = criterion(outputs, labels)\n",
                "            v_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "            v_correct += (preds == labels.data).sum().item()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss/len(train_loader))\n",
                "    history['val_loss'].append(v_loss/len(val_loader))\n",
                "    history['train_acc'].append(tr_correct/len(train_set))\n",
                "    history['val_acc'].append(v_correct/len(val_set))\n",
                "\n",
                "# TÍNH TOÁN METRICS\n",
                "y_true, y_pred = [], []\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        outputs = model(inputs.to(DEVICE)); _, preds = torch.max(outputs, 1)\n",
                "        y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n",
                "\n",
                "acc = accuracy_score(y_true, y_pred)\n",
                "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
                "mse = mean_squared_error(y_true, y_pred); rmse = np.sqrt(mse); r2 = r2_score(y_true, y_pred)\n",
                "\n",
                "# LƯU KẾT QUẢ\n",
                "report_data = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
                "report_data['regression_metrics'] = {'mse': float(mse), 'rmse': float(rmse), 'r2_score': float(r2), 'accuracy': float(acc)}\n",
                "with open(os.path.join(m_res_path, 'report.json'), 'w') as f: json.dump(report_data, f, indent=4)\n",
                "\n",
                "# VẼ BIỂU ĐỒ TỔNG HỢP CHO MODEL\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "axes[0].plot(history['train_acc'], label='Train Acc'); axes[0].plot(history['val_acc'], label='Val Acc'); axes[0].set_title('Accuracy'); axes[0].legend()\n",
                "axes[1].plot(history['train_loss'], label='Train Loss'); axes[1].plot(history['val_loss'], label='Val Loss'); axes[1].set_title('Loss'); axes[1].legend()\n",
                "plt.savefig(os.path.join(m_res_path, 'metrics_curves.png')); plt.show()\n",
                "\n",
                "print(f'Done {m_name}: Accuracy={acc:.4f}')\n",
                "del model; torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Mô hình: ResNet50\n",
                "**Mô tả:** Residual depth 50.\n",
                "\n",
                "**Tối ưu hóa:** Sử dụng Mixed Precision (AMP) và Multi-worker DataLoading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Huấn luyện TỐI ƯU mô hình: ResNet50\n",
                "m_name = 'ResNet50'\n",
                "m_res_path = os.path.join(RESULT_PATH, m_name)\n",
                "os.makedirs(m_res_path, exist_ok=True)\n",
                "\n",
                "print(f'--- Đang khởi tạo mô hình: {m_name} ---')\n",
                "model = get_model(m_name, NUM_CLASSES)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
                "scaler = torch.cuda.amp.GradScaler() # AMP\n",
                "\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train(); tr_loss, tr_correct = 0, 0\n",
                "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Train]')\n",
                "    for inputs, labels in pbar:\n",
                "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        with torch.cuda.amp.autocast(): # AMP Forward\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward() # AMP Backward\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        tr_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "        tr_correct += (preds == labels.data).sum().item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    model.eval(); v_loss, v_correct = 0, 0\n",
                "    with torch.no_grad():\n",
                "        vbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Val]')\n",
                "        for inputs, labels in vbar:\n",
                "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "            with torch.cuda.amp.autocast():\n",
                "                outputs = model(inputs); loss = criterion(outputs, labels)\n",
                "            v_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "            v_correct += (preds == labels.data).sum().item()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss/len(train_loader))\n",
                "    history['val_loss'].append(v_loss/len(val_loader))\n",
                "    history['train_acc'].append(tr_correct/len(train_set))\n",
                "    history['val_acc'].append(v_correct/len(val_set))\n",
                "\n",
                "# TÍNH TOÁN METRICS\n",
                "y_true, y_pred = [], []\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        outputs = model(inputs.to(DEVICE)); _, preds = torch.max(outputs, 1)\n",
                "        y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n",
                "\n",
                "acc = accuracy_score(y_true, y_pred)\n",
                "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
                "mse = mean_squared_error(y_true, y_pred); rmse = np.sqrt(mse); r2 = r2_score(y_true, y_pred)\n",
                "\n",
                "# LƯU KẾT QUẢ\n",
                "report_data = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
                "report_data['regression_metrics'] = {'mse': float(mse), 'rmse': float(rmse), 'r2_score': float(r2), 'accuracy': float(acc)}\n",
                "with open(os.path.join(m_res_path, 'report.json'), 'w') as f: json.dump(report_data, f, indent=4)\n",
                "\n",
                "# VẼ BIỂU ĐỒ TỔNG HỢP CHO MODEL\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "axes[0].plot(history['train_acc'], label='Train Acc'); axes[0].plot(history['val_acc'], label='Val Acc'); axes[0].set_title('Accuracy'); axes[0].legend()\n",
                "axes[1].plot(history['train_loss'], label='Train Loss'); axes[1].plot(history['val_loss'], label='Val Loss'); axes[1].set_title('Loss'); axes[1].legend()\n",
                "plt.savefig(os.path.join(m_res_path, 'metrics_curves.png')); plt.show()\n",
                "\n",
                "print(f'Done {m_name}: Accuracy={acc:.4f}')\n",
                "del model; torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Mô hình: ShuffleNetV2\n",
                "**Mô tả:** Siêu nhẹ.\n",
                "\n",
                "**Tối ưu hóa:** Sử dụng Mixed Precision (AMP) và Multi-worker DataLoading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Huấn luyện TỐI ƯU mô hình: ShuffleNetV2\n",
                "m_name = 'ShuffleNetV2'\n",
                "m_res_path = os.path.join(RESULT_PATH, m_name)\n",
                "os.makedirs(m_res_path, exist_ok=True)\n",
                "\n",
                "print(f'--- Đang khởi tạo mô hình: {m_name} ---')\n",
                "model = get_model(m_name, NUM_CLASSES)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
                "scaler = torch.cuda.amp.GradScaler() # AMP\n",
                "\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train(); tr_loss, tr_correct = 0, 0\n",
                "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Train]')\n",
                "    for inputs, labels in pbar:\n",
                "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        with torch.cuda.amp.autocast(): # AMP Forward\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward() # AMP Backward\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        tr_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "        tr_correct += (preds == labels.data).sum().item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    model.eval(); v_loss, v_correct = 0, 0\n",
                "    with torch.no_grad():\n",
                "        vbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Val]')\n",
                "        for inputs, labels in vbar:\n",
                "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "            with torch.cuda.amp.autocast():\n",
                "                outputs = model(inputs); loss = criterion(outputs, labels)\n",
                "            v_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "            v_correct += (preds == labels.data).sum().item()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss/len(train_loader))\n",
                "    history['val_loss'].append(v_loss/len(val_loader))\n",
                "    history['train_acc'].append(tr_correct/len(train_set))\n",
                "    history['val_acc'].append(v_correct/len(val_set))\n",
                "\n",
                "# TÍNH TOÁN METRICS\n",
                "y_true, y_pred = [], []\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        outputs = model(inputs.to(DEVICE)); _, preds = torch.max(outputs, 1)\n",
                "        y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n",
                "\n",
                "acc = accuracy_score(y_true, y_pred)\n",
                "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
                "mse = mean_squared_error(y_true, y_pred); rmse = np.sqrt(mse); r2 = r2_score(y_true, y_pred)\n",
                "\n",
                "# LƯU KẾT QUẢ\n",
                "report_data = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
                "report_data['regression_metrics'] = {'mse': float(mse), 'rmse': float(rmse), 'r2_score': float(r2), 'accuracy': float(acc)}\n",
                "with open(os.path.join(m_res_path, 'report.json'), 'w') as f: json.dump(report_data, f, indent=4)\n",
                "\n",
                "# VẼ BIỂU ĐỒ TỔNG HỢP CHO MODEL\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "axes[0].plot(history['train_acc'], label='Train Acc'); axes[0].plot(history['val_acc'], label='Val Acc'); axes[0].set_title('Accuracy'); axes[0].legend()\n",
                "axes[1].plot(history['train_loss'], label='Train Loss'); axes[1].plot(history['val_loss'], label='Val Loss'); axes[1].set_title('Loss'); axes[1].legend()\n",
                "plt.savefig(os.path.join(m_res_path, 'metrics_curves.png')); plt.show()\n",
                "\n",
                "print(f'Done {m_name}: Accuracy={acc:.4f}')\n",
                "del model; torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Mô hình: DenseNet121\n",
                "**Mô tả:** Kết nối dày đặc.\n",
                "\n",
                "**Tối ưu hóa:** Sử dụng Mixed Precision (AMP) và Multi-worker DataLoading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Huấn luyện TỐI ƯU mô hình: DenseNet121\n",
                "m_name = 'DenseNet121'\n",
                "m_res_path = os.path.join(RESULT_PATH, m_name)\n",
                "os.makedirs(m_res_path, exist_ok=True)\n",
                "\n",
                "print(f'--- Đang khởi tạo mô hình: {m_name} ---')\n",
                "model = get_model(m_name, NUM_CLASSES)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
                "scaler = torch.cuda.amp.GradScaler() # AMP\n",
                "\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train(); tr_loss, tr_correct = 0, 0\n",
                "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Train]')\n",
                "    for inputs, labels in pbar:\n",
                "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        with torch.cuda.amp.autocast(): # AMP Forward\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward() # AMP Backward\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        tr_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "        tr_correct += (preds == labels.data).sum().item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    model.eval(); v_loss, v_correct = 0, 0\n",
                "    with torch.no_grad():\n",
                "        vbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Val]')\n",
                "        for inputs, labels in vbar:\n",
                "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "            with torch.cuda.amp.autocast():\n",
                "                outputs = model(inputs); loss = criterion(outputs, labels)\n",
                "            v_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "            v_correct += (preds == labels.data).sum().item()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss/len(train_loader))\n",
                "    history['val_loss'].append(v_loss/len(val_loader))\n",
                "    history['train_acc'].append(tr_correct/len(train_set))\n",
                "    history['val_acc'].append(v_correct/len(val_set))\n",
                "\n",
                "# TÍNH TOÁN METRICS\n",
                "y_true, y_pred = [], []\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        outputs = model(inputs.to(DEVICE)); _, preds = torch.max(outputs, 1)\n",
                "        y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n",
                "\n",
                "acc = accuracy_score(y_true, y_pred)\n",
                "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
                "mse = mean_squared_error(y_true, y_pred); rmse = np.sqrt(mse); r2 = r2_score(y_true, y_pred)\n",
                "\n",
                "# LƯU KẾT QUẢ\n",
                "report_data = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
                "report_data['regression_metrics'] = {'mse': float(mse), 'rmse': float(rmse), 'r2_score': float(r2), 'accuracy': float(acc)}\n",
                "with open(os.path.join(m_res_path, 'report.json'), 'w') as f: json.dump(report_data, f, indent=4)\n",
                "\n",
                "# VẼ BIỂU ĐỒ TỔNG HỢP CHO MODEL\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "axes[0].plot(history['train_acc'], label='Train Acc'); axes[0].plot(history['val_acc'], label='Val Acc'); axes[0].set_title('Accuracy'); axes[0].legend()\n",
                "axes[1].plot(history['train_loss'], label='Train Loss'); axes[1].plot(history['val_loss'], label='Val Loss'); axes[1].set_title('Loss'); axes[1].legend()\n",
                "plt.savefig(os.path.join(m_res_path, 'metrics_curves.png')); plt.show()\n",
                "\n",
                "print(f'Done {m_name}: Accuracy={acc:.4f}')\n",
                "del model; torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Mô hình: EfficientNetV2\n",
                "**Mô tả:** Tối ưu quy mô.\n",
                "\n",
                "**Tối ưu hóa:** Sử dụng Mixed Precision (AMP) và Multi-worker DataLoading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Huấn luyện TỐI ƯU mô hình: EfficientNetV2\n",
                "m_name = 'EfficientNetV2'\n",
                "m_res_path = os.path.join(RESULT_PATH, m_name)\n",
                "os.makedirs(m_res_path, exist_ok=True)\n",
                "\n",
                "print(f'--- Đang khởi tạo mô hình: {m_name} ---')\n",
                "model = get_model(m_name, NUM_CLASSES)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
                "scaler = torch.cuda.amp.GradScaler() # AMP\n",
                "\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train(); tr_loss, tr_correct = 0, 0\n",
                "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Train]')\n",
                "    for inputs, labels in pbar:\n",
                "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        with torch.cuda.amp.autocast(): # AMP Forward\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward() # AMP Backward\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        tr_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "        tr_correct += (preds == labels.data).sum().item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    model.eval(); v_loss, v_correct = 0, 0\n",
                "    with torch.no_grad():\n",
                "        vbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Val]')\n",
                "        for inputs, labels in vbar:\n",
                "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "            with torch.cuda.amp.autocast():\n",
                "                outputs = model(inputs); loss = criterion(outputs, labels)\n",
                "            v_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "            v_correct += (preds == labels.data).sum().item()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss/len(train_loader))\n",
                "    history['val_loss'].append(v_loss/len(val_loader))\n",
                "    history['train_acc'].append(tr_correct/len(train_set))\n",
                "    history['val_acc'].append(v_correct/len(val_set))\n",
                "\n",
                "# TÍNH TOÁN METRICS\n",
                "y_true, y_pred = [], []\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        outputs = model(inputs.to(DEVICE)); _, preds = torch.max(outputs, 1)\n",
                "        y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n",
                "\n",
                "acc = accuracy_score(y_true, y_pred)\n",
                "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
                "mse = mean_squared_error(y_true, y_pred); rmse = np.sqrt(mse); r2 = r2_score(y_true, y_pred)\n",
                "\n",
                "# LƯU KẾT QUẢ\n",
                "report_data = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
                "report_data['regression_metrics'] = {'mse': float(mse), 'rmse': float(rmse), 'r2_score': float(r2), 'accuracy': float(acc)}\n",
                "with open(os.path.join(m_res_path, 'report.json'), 'w') as f: json.dump(report_data, f, indent=4)\n",
                "\n",
                "# VẼ BIỂU ĐỒ TỔNG HỢP CHO MODEL\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "axes[0].plot(history['train_acc'], label='Train Acc'); axes[0].plot(history['val_acc'], label='Val Acc'); axes[0].set_title('Accuracy'); axes[0].legend()\n",
                "axes[1].plot(history['train_loss'], label='Train Loss'); axes[1].plot(history['val_loss'], label='Val Loss'); axes[1].set_title('Loss'); axes[1].legend()\n",
                "plt.savefig(os.path.join(m_res_path, 'metrics_curves.png')); plt.show()\n",
                "\n",
                "print(f'Done {m_name}: Accuracy={acc:.4f}')\n",
                "del model; torch.cuda.empty_cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Mô hình: ConvNeXt_Tiny\n",
                "**Mô tả:** Hiện đại (SOTA).\n",
                "\n",
                "**Tối ưu hóa:** Sử dụng Mixed Precision (AMP) và Multi-worker DataLoading."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "## Huấn luyện TỐI ƯU mô hình: ConvNeXt_Tiny\n",
                "m_name = 'ConvNeXt_Tiny'\n",
                "m_res_path = os.path.join(RESULT_PATH, m_name)\n",
                "os.makedirs(m_res_path, exist_ok=True)\n",
                "\n",
                "print(f'--- Đang khởi tạo mô hình: {m_name} ---')\n",
                "model = get_model(m_name, NUM_CLASSES)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
                "scaler = torch.cuda.amp.GradScaler() # AMP\n",
                "\n",
                "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train(); tr_loss, tr_correct = 0, 0\n",
                "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Train]')\n",
                "    for inputs, labels in pbar:\n",
                "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "        optimizer.zero_grad()\n",
                "        with torch.cuda.amp.autocast(): # AMP Forward\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, labels)\n",
                "        scaler.scale(loss).backward() # AMP Backward\n",
                "        scaler.step(optimizer)\n",
                "        scaler.update()\n",
                "        tr_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "        tr_correct += (preds == labels.data).sum().item()\n",
                "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
                "    \n",
                "    model.eval(); v_loss, v_correct = 0, 0\n",
                "    with torch.no_grad():\n",
                "        vbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} [Val]')\n",
                "        for inputs, labels in vbar:\n",
                "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
                "            with torch.cuda.amp.autocast():\n",
                "                outputs = model(inputs); loss = criterion(outputs, labels)\n",
                "            v_loss += loss.item(); _, preds = torch.max(outputs, 1)\n",
                "            v_correct += (preds == labels.data).sum().item()\n",
                "    \n",
                "    history['train_loss'].append(tr_loss/len(train_loader))\n",
                "    history['val_loss'].append(v_loss/len(val_loader))\n",
                "    history['train_acc'].append(tr_correct/len(train_set))\n",
                "    history['val_acc'].append(v_correct/len(val_set))\n",
                "\n",
                "# TÍNH TOÁN METRICS\n",
                "y_true, y_pred = [], []\n",
                "model.eval()\n",
                "with torch.no_grad():\n",
                "    for inputs, labels in test_loader:\n",
                "        outputs = model(inputs.to(DEVICE)); _, preds = torch.max(outputs, 1)\n",
                "        y_true.extend(labels.numpy()); y_pred.extend(preds.cpu().numpy())\n",
                "\n",
                "acc = accuracy_score(y_true, y_pred)\n",
                "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
                "mse = mean_squared_error(y_true, y_pred); rmse = np.sqrt(mse); r2 = r2_score(y_true, y_pred)\n",
                "\n",
                "# LƯU KẾT QUẢ\n",
                "report_data = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
                "report_data['regression_metrics'] = {'mse': float(mse), 'rmse': float(rmse), 'r2_score': float(r2), 'accuracy': float(acc)}\n",
                "with open(os.path.join(m_res_path, 'report.json'), 'w') as f: json.dump(report_data, f, indent=4)\n",
                "\n",
                "# VẼ BIỂU ĐỒ TỔNG HỢP CHO MODEL\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
                "axes[0].plot(history['train_acc'], label='Train Acc'); axes[0].plot(history['val_acc'], label='Val Acc'); axes[0].set_title('Accuracy'); axes[0].legend()\n",
                "axes[1].plot(history['train_loss'], label='Train Loss'); axes[1].plot(history['val_loss'], label='Val Loss'); axes[1].set_title('Loss'); axes[1].legend()\n",
                "plt.savefig(os.path.join(m_res_path, 'metrics_curves.png')); plt.show()\n",
                "\n",
                "print(f'Done {m_name}: Accuracy={acc:.4f}')\n",
                "del model; torch.cuda.empty_cache()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}